\section{Offline pose training} \label{sec:pose-generation}
An algorithm have been produced which can automatically generate a set of
poses, or read a set of poses from file. In this way, poses for a given object
can be generated, and heuristic poses can be given by the programmer as a hint
for the grasping algorithm.  

Each grasping pose is associated with a \emph{preference score} $P_{g}$: this will be taken
into account as a second-level sorting value for grasps, meaning that the
grasping algorithm will first search for the grasp with the lower score (i.e.
intersection volume, as described in sec. \ref{sec:grasp_score}, but in case of
a tie, it will prefer the grasp with a higher preference score.

The parameter used to assign to each grasp a preference score is the supposed
easiness to grasp the object without having it dropped during the subsequent
movement phase: for example, for the duck-toy object shown in fig.
\ref{fig:duck-toy-grasps}, a grasp done with a sucker on the plastic covering
should work properly enough, but, being the plastic covering not rigid, the
object is not sure to be taken without possibility of falling. Instead, a grasp
done with clamps on the rigid, cardboard top of the envelope would work almost
for sure. In this case, both poses would be added to the grasp list, but the
latter would be preferred if both would not make the gripper collide with the
rest of the scene.

The pose generation has been splitted into two, minor problems: indentifying a
set of points onto the object which can be used for efficient grasping, and
assigning to each point a reference frame into the gripper's model; after these
informations have been combined, the desired gripping pose is well-defined, as the
whole pose of the gripper can be computed. Problem splitting is useful in this
case, as the two parts are independent and only a little number of gripper's
reference frames -- the one corresponding to the gripper's tools -- are actually
useful for grasping. On the other hand, the problem of  generating poses for a generic
reference frame can be solved by exploiting the geometric properties of the
object itself, and this makes the algorithm agnostic with respect to the actual
gripper's shape and thus more flexible and general.

The point of connection between the two subproblems has been constrainted at the
implementation's level for simplicity's sake: all of the generated pose
points will be associated to a vector at generation time. This vector will
coincide with the tool's $Z$ axis at the time of pose binding. When describing
the pose of the tools associated with a certain set of gripping poses, it will
be sufficient to set their $Z$ axis into the operative direction (e.g. suiction
direction for suckers) in order to have the generation algorithm automatically
bind points to an actual gripper's pose.

\subsection{Pose generations on a line and on a plane's surface} \label{sec:pose-generation-line-plane}
If a set of poses on a plane surface must be generated, a good method is simply
to sample the plane onto equally distanced points. Starting from the center of
the plane, which would be the preferred point for the gripper to land onto,
samples can be taken at increasing distances until the border of the surface is
reached. when doing this, it assumed that the algorithm requiring pose
generation will already have taken into account a good margin from the gripper
to operate, and so none of the poses will actually result into a gripping
failure. With this in mind, a good preference score can be obtained as the
squared distance from the gripping point $\vec{p}$ to the center $\vec{c}$ of the surface:

\begin{equation}
P_{g}=(\vec{p}-\vec{c})(\vec{p}-vec{c})^\tau
\end{equation}

Regarding the pose's orientation, the $Z$ axis is well-defined, as it will
coincide with the plane's perpendicular vector. Two cases have been considered,
as it is useful to have two different descriptions for the plane's section: if
the plane is described using a width and a height vector, named $\vec{w}$ and $\vec{h}$ the perpendicular
direction is the direction of their product:

\begin{equation}
  \vec{z_{g}}=\vec{w} \times \vec{h}
\end{equation}

On the other hand, it is helpful sometimes to describe the plane by its
perpendicular direction and center point: in this case, the $Z$ axis will just
be the same as the perpendicular vector.

In the case that the path on which the gripper can land is a straight
line segment, for which the direction vector is $l$, the same considerations apply. However, the $Z$ axis is
not unique anymore in this case: it is, instead, computed by giving
to the pose, as a parameter, a second vector describing the
perpendicular direction to the line, $\vec{p_l}$, belonging to the
same physical plane the line refers to onto the object. The $Z$ axis
for the grasp can be computed as the cross product of the two
directional vectors:

\begin{equation}
  \vec{z_{g}}=\vec{l} \times \vec{p_l}
\end{equation}

The need for supplying a third vector $\vec{p_l}$ instead of directly
supplying the grasp direction $\vec{z_g}$ is justified by the need of
pose constraining, as explained in sec.~\ref{sec:pose-constraining}.


It is important to notice that, representing the axis of a grasp tool,
the direction of $z_g$ is important to distinguish. It will be in fact
used to determine on which side of the object $z_g$ refers to the
grasping tool will have to land, i.e. to distinguish between the
external and internal sides of the objects. In particular, for the
pose generation on a line, as $\vec{p_l}$ direction is predetermined
(by the user) based on the needs of the grasping tool, and the line
directional vector $l$ is computed as $\vec{l}=\vec{p_2}-\vec{p_1}$,
being $\vec{p_2}$ and $\vec{p_1}$ the two extremes of the line
segment, the order in which $\vec{p_2}$ and $\vec{p_1}$ are considered
is important.

Apart from these considerations, using these two simple primitives,
plus custom-generated points (with custom preference scores), most of
the commonly used shapes can be described. In particular, planes are
useful to describe grasping points on cuboidal shapes, while lines are
used in the same context, but in the case in which the grasping
direction must be more constrained and the surface the line refers to
is particularly narrow (e.g. in the case of a grasp on the cardboard
top for the toy duck of fig.~\ref{fig:duck-toy-grasps}).

An easy possibility to extend this last generation algorithm, instead
of having it generate points on a straight line, is the use of
parametric functions $(x,y)=f(t)$; by sampling these at regular $t$
intervals, most of the odd shapes can be described easily. This has
not been implemented into the pose generation system, but the
possibility to do it easily has been left into it, as a part of the
general expandable structure of the whole system.

\subsection{Pose constraining on different axis} \label{sec:pose-constraining}
Associating with each gripper's position a single $Z$ axis constraints
its operation, but is not enough to perfectly define the pose that the
gripper will have: in-plane rotation of the gripper over the $Z$ axis
of its gripping tool will, in fact, leave the poses' conditions
satisfied and change a lot the robot's configuration -- especially if
the selected tool is not in line with the main gripper axis, as in the
case of the suckers of the gripper used as a reference into this
project.

This is done by purpose, as constraining the in-plane rotation of the
gripper with a directional vector in the relative coordinate system of
the object would force the gripper to rotate together with the object,
which can positioned with every orientation into the scene, and thus
would cause the robot assume unnatural (or impossible) configurations
in many cases; a trivial solution would be to generate poses at
runtime after knowing the full pose of the objects, but this would
both harm the modularity requirement of the system (with the solution
presented in this section, poses are bound to the object, which thus
forms an independent blob of abstraction) and the possibility to add
custom poses to the possibility list, which should not be discarded as
heuristic is generally a good addition to every automatic system.

Instead, the proposed solution is to associate with each pose a set of
flags indicating whether each of the three axis of the gripper is
constrained over a particular direction, and let the robot fit the
pose independently when grasping. This is particularly useful in the
case as this in which different tools have to be associated to a set
of poses generated for a same object: for a sucker, for example, the
in-plane rotation is totally non influential, as suckers have
rotational simmetry; for the gripper hands, instead, grasp direction
must be obviously constrained, otherwise the grasp will not be effective.

When generating poses, each sets a firm contraint over the gripping
tool's $Z$ axis, as described in
sec.~\ref{sec:pose-generation-line-plane}; if the poses are generated
on a plane, this is supposed to be big enough for the other directions
to be considered equally important: thus, no constraints are set
neither for the $X$ nor for the $Y$ axis. On the other hand,
nonetheless, generating poses over a straight line segment requires
defining a gripping plane, and will be probabily used for grasping
over narrow regions: thus, a vector constraining the $X$ axis is set;
this will be both used to constrain the gripper tool and to define the
plane to which this narrow surface belongs, which can be used in turn
to find the perpendicular $Z$ axis by cross-product as already explained.
