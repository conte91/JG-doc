\section{Offline pose training} \label{sec:pose-generation}
An algorithm have been produced which can automatically generate a set of
poses, or read a set of poses from file. In this way, poses for a given object
can be generated, and heuristic poses can be given by the programmer as a hint
for the grasping algorithm.  

Each grasping pose is associated with a \emph{preference score} $P_{g}$: this will be taken
into account as a second-level sorting value for grasps, meaning that the
grasping algorithm will first search for the grasp with the lower score (i.e.
intersection volume, as described in sec. \ref{sec:grasp_score}, but in case of
a tie, it will prefer the grasp with a higher preference score.

The parameter used to assign to each grasp a preference score is the supposed
easiness to grasp the object without having it dropped during the subsequent
movement phase: for example, for the duck-toy object shown in fig.
\ref{fig:duck-toy-grasps}, a grasp done with a sucker on the plastic covering
should work properly enough, but, being the plastic covering not rigid, the
object is not sure to be taken without possibility of falling. Instead, a grasp
done with clamps on the rigid, cardboard top of the envelope would work almost
for sure. In this case, both poses would be added to the grasp list, but the
latter would be preferred if both would not make the gripper collide with the
rest of the scene.

The pose generation has been splitted into two, minor problems: indentifying a
set of points onto the object which can be used for efficient grasping, and
assigning to each point a reference frame into the gripper's model; after these
informations have been combined, the desired gripping pose is well-defined, as the
whole pose of the gripper can be computed. Problem splitting is useful in this
case, as the two parts are independent and only a little number of gripper's
reference frames -- the one corresponding to the gripper's tools -- are actually
useful for grasping. On the other hand, the problem of  generating poses for a generic
reference frame can be solved by exploiting the geometric properties of the
object itself, and this makes the algorithm agnostic with respect to the actual
gripper's shape and thus more flexible and general.

The point of connection between the two subproblems has been constrainted at the
implementation's level for simplicity's sake: all of the generated pose
points will be associated to a vector at generation time. This vector will
coincide with the tool's $Z$ axis at the time of pose binding. When describing
the pose of the tools associated with a certain set of gripping poses, it will
be sufficient to set their $Z$ axis into the operative direction (e.g. suiction
direction for suckers) in order to have the generation algorithm automatically
bind points to an actual gripper's pose.

\subsection{Pose generations on a line and on a plane's surface} \label{sec:pose-generation-line-plane}
If a set of poses on a plane surface must be generated, a good method is simply
to sample the plane onto equally distanced points. Starting from the center of
the plane, which would be the preferred point for the gripper to land onto,
samples can be taken at increasing distances until the border of the surface is
reached. when doing this, it assumed that the algorithm requiring pose
generation will already have taken into account a good margin from the gripper
to operate, and so none of the poses will actually result into a gripping
failure. With this in mind, a good preference score can be obtained as the
squared distance from the gripping point $\vec{p}$ to the center $\vec{c}$ of the surface:

\begin{equation}
P_{g}=(\vec{p}-\vec{c})(\vec{p}-vec{c})^\tau
\end{equation}

Regarding the pose's orientation, the $Z$ axis is well-defined, as it will
coincide with the plane's perpendicular vector. Two cases have been considered,
as it is useful to have two different descriptions for the plane's section: if
the plane is described using a width and a height vector, named $\vec{w}$ and $\vec{h}$ the perpendicular
direction is the direction of their product:

\begin{equation}
  \vec{z_{g}}=\vec{w} \times \vec{h}
\end{equation}

On the other hand, it is helpful sometimes to describe the plane by its
perpendicular direction and center point: in this case, the $Z$ axis will just
be the same as the perpendicular vector.

In the case that the path on which the gripper can land is a straight
line segment, for which the direction vector is $l$, the same considerations apply. However, the $Z$ axis is
not unique anymore in this case: it is, instead, computed by giving
to the pose, as a parameter, a second vector describing the
perpendicular direction to the line, $\vec{p_l}$, belonging to the
same physical plane the line refers to onto the object. The $Z$ axis
for the grasp can be computed as the cross product of the two
directional vectors:

\begin{equation}
  \vec{z_{g}}=\vec{l} \times \vec{p_l}
\end{equation}

The need for supplying a third vector $\vec{p_l}$ instead of directly
supplying the grasp direction $\vec{z_g}$ is justified by the need of
pose constraining, as explained in sec.~\ref{sec:pose-constraining}.


It is important to notice that, representing the axis of a grasp tool,
the direction of $z_g$ is important to distinguish. It will be in fact
used to determine on which side of the object $z_g$ refers to the
grasping tool will have to land, i.e. to distinguish between the
external and internal sides of the objects. In particular, for the
pose generation on a line, as $\vec{p_l}$ direction is predetermined
(by the user) based on the needs of the grasping tool, and the line
directional vector $l$ is computed as $\vec{l}=\vec{p_2}-\vec{p_1}$,
being $\vec{p_2}$ and $\vec{p_1}$ the two extremes of the line
segment, the order in which $\vec{p_2}$ and $\vec{p_1}$ are considered
is important.

Apart from these considerations, using these two simple primitives,
plus custom-generated points (with custom preference scores), most of
the commonly used shapes can be described. In particular, planes are
useful to describe grasping points on cuboidal shapes, while lines are
used in the same context, but in the case in which the grasping
direction must be more constrained and the surface the line refers to
is particularly narrow (e.g. in the case of a grasp on the cardboard
top for the toy duck of fig.~\ref{fig:duck-toy-grasps}).

An easy possibility to extend this last generation algorithm, instead
of having it generate points on a straight line, is the use of
parametric functions $(x,y)=f(t)$; by sampling these at regular $t$
intervals, most of the odd shapes can be described easily. This has
not been implemented into the pose generation system, but the
possibility to do it easily has been left into it, as a part of the
general expandable structure of the whole system.

\subsection{Pose constraining on different axes} \label{sec:pose-constraining}
Associating with each gripper's position a single $Z$ axis constraints
its operation, but is not enough to perfectly define the pose that the
gripper will have: in-plane rotation of the gripper over the $Z$ axis
of its gripping tool will, in fact, leave the poses' conditions
satisfied and change a lot the robot's configuration -- especially if
the selected tool is not in line with the main gripper axis, as in the
case of the suckers of the gripper used as a reference into this
project.

This is done by purpose, as constraining the in-plane rotation of the
gripper with a directional vector in the relative coordinate system of
the object would force the gripper to rotate together with the object,
which can positioned with every orientation into the scene, and thus
would cause the robot assume unnatural (or impossible) configurations
in many cases; a trivial solution would be to generate poses at
runtime after knowing the full pose of the objects, but this would
both harm the modularity requirement of the system (with the solution
presented in this section, poses are bound to the object, which thus
forms an independent blob of abstraction) and the possibility to add
custom poses to the possibility list, which should not be discarded as
heuristic is generally a good addition to every automatic system.

Instead, the proposed solution is to associate with each pose a set of
flags indicating whether each of the three axis of the gripper is
constrained over a particular direction, and let the robot fit the
pose independently when grasping. This is particularly useful in the
case as this in which different tools have to be associated to a set
of poses generated for a same object: for a sucker, for example, the
in-plane rotation is totally non influential, as suckers have
rotational simmetry; for the gripper hands, instead, grasp direction
must be obviously constrained, otherwise the grasp will not be effective.

When generating poses, each sets a firm contraint over the gripping
tool's $Z$ axis, as described in
sec.~\ref{sec:pose-generation-line-plane}; if the poses are generated
on a plane, this is supposed to be big enough for the other directions
to be considered equally important: thus, no constraints are set
neither for the $X$ nor for the $Y$ axis. On the other hand,
nonetheless, generating poses over a straight line segment requires
defining a gripping plane, and will be probabily used for grasping
over narrow regions: thus, a vector constraining the $X$ axis is set;
this will be both used to constrain the gripper tool and to define the
plane to which this narrow surface belongs, which can be used in turn
to find the perpendicular $Z$ axis by cross-product as already explained.

When it is time for the gripper to obtain a concrete pose for grasping
the object, constraints informations are used to extract a rotation
matrix for the tool in object coordinates.

The chosen default strategy for choosing among the possible tool's
configurations is to assign to the gripper a rotational-only frame, called \emph{base
  frame}, which corresponds to the preferred pose $R_{\text{ideal}}$ of the gripper in
global coodinates; in an ideal situation, the gripper will keep its
preferred orientation and the tool will be aligned to the picking
axes. If, however, this is not possible, the minimal rotation will be
found which aligns the ideal frame with a valid one.

More specifically, two cases can be considered, depending on whether 
the pose is constrained over at least two axes or not. In both cases,
the rotation matrix of the tool $R_t$ is obtained. The third case in
which no constraints are given (which could come from user-defined
grasps) is trivial as the rotation matrix for the tool can be found by
transforming the ideal tool's pose in tool coordinates:

\begin{equation}\label{eqn:trivial-pose-constraining}
  R_t = R_{\text{ideal}} R_{\text{tool}}
\end{equation}

Here, $R_{\text{tool}}$ represents the rotation matrix of the tool's
coordinate system with respect to the gripper's one.

If at least two axes have been defined for the grasp, this results to
be fully constrained; the third axis of the tool can be
found by applying the additional constraint that the reference system
of the tool must be right-handed:

\begin{eqnarray}
  \vec{Z_t} &=& \vec{X_t} \times \vec{Y_t} \\
  \vec{Y_t} &=& \vec{Z_t} \times \vec{X_t} \\
  \vec{X_t} &=& \vec{Y_t} \times \vec{Z_t} 
\end{eqnarray}

After knowing all of the needed axes for the tool in object's
coordinates, the rotation matrix $R_t$ can be obtained by using the
three vectors as generators for a vectorial base, whose change of
base's matrix represents the desired rotation:

\begin{equation} 
  R_t = \left( \begin{array}{c|c|c} \vec{X_t} & \vec{Y_t} &
    \vec{Z_t} \end{array} \right)
\end{equation}

On the other hand, if only one constraint is given for one of the
axes, it is possible to relax the gripper's pose to be as near as
possible to the ideal one. In this example, the hypothesis is that the
$\vec{Z}$ axis is constrained, but it is trivial to extend this
procedure to other cases as needed.

In order to align the ideal pose with the required one, the minimal
rotation between the two is searched. Thanks to Euler's rotation
theorem, this rotation exists for sure, and can be represented
through and angle $\alpha, 0 \leq \alpha \leq \pi$ of rotation, and
the axis around which to rotate in counter-clockwise direction,
represented as a unit vector $V_{\text{axis}}
= \begin{pmatrix}x_{\text{axis}} \\ y_{\text{axis}} \\ z_{\text{axis}}
\end{pmatrix} , \lVert V_{\text{axis}} \rVert = 1$.

First, the tool's rotation $R_{t,b}$ with regards to the gripper's
base frame $R_b$
is computed from the tool's rotation $R_t$ with respect to the
gripper's local frame.
Then, the ideal gripper's orientation, i.e. the base frame,  is ported
into the coordinate system the object refers to using the inverse of
the object's rotational transform $R_o$.
The previously found transformation is used to obtain the ideal pose of the
tool with respect to the object's coordinate system:

\begin{eqnarray}
  R_{t,b} &=& R_b^{-1} R_t\\
  R_{t,\text{ideal}} &=& R_{t,b} R_o^{-1} R_{b} \\
\end{eqnarray}

This transformation matrix is applied to the tools's $\vec{Z_t}$ axis to found
were it would land into an ideal situation:

\begin{equation}
  \vec{Z_{t,\text{ideal}}}  = R_{t,\text{ideal}}\begin{pmatrix}0\\0\\1
  \end{pmatrix}
\end{equation}

Knowing the desired tool $Z$ axis $Z_t$ makes it possible to compute
both the angle and the axis of the minimum rotation between the two:

\begin{eqnarray}
  \alpha &=& \left\{
  \begin{array}{lcr}
    0 & \text{when} & \vec{Z_{t,\text{ideal}}} \approx
    \vec{Z_{t,\text{real}}} ,\\
    \pi & \text{when} & \vec{Z_{t,\text{ideal}}} \approx
    -\vec{Z_{t,\text{real}}} ,\\
    \cos^{-1}\left(
    \vec{Z_{t,\text{ideal}}}\vec{Z_{t,\text{real}}}^{\tau}  \right) &
    & \text{otherwise.}
  \end{array} \right. \\
  \vec{V_{\text{axis}}} &=& \left\{
  \begin{array}{lcr}
    \begin{pmatrix}
      1\\0\\0
    \end{pmatrix} & \text{when} & \vec{Z_{t,\text{ideal}}} \approx
    \pm \vec{Z_{t,\text{real}}}, \\
    \vec{Z_{\text{ideal}}} \times \vec{Z_{\text{real}}} &
    & \text{otherwise.} 
  \end{array}\right.
\end{eqnarray}

Here, in the case that the two vectors are on the same line
($\alpha=\pi$ or $\alpha=0$) the rotation vector can be actually
chosen freely as a combination of the $\vec{X}$ and $\vec{Y}$ vectors;
however, the $\vec{X}$ vector as been chosen always for simplicity's sake.

After obtaining a representation of the minimum rotation  that
aligns the ideal tool $Z$ axis with the correct one, it can be applied
to the whole ideal tool orientation, computed at the start of this
process, to obtain the correct alignement of the tool in object
coordinates.

\begin{equation}
  R_t=\text{Rot}(\alpha,V_{\text{axis}}) R_{t,\text{ideal}}
\end{equation}

When a rotation matrix has been obtained with any of the methords
decribed before, the whole tool pose, represented as an affine
transformation, can be obtained by knowing the attach point $T_g$ of
the grasp, as it is stored into the pose information: 

\begin{equation}
  P_{\text{tool}}=\left( \begin{array}{ccc|c}
    \multicolumn{3}{c}{R_t} & T_g \\
    \hline 
    0 & 0 & 0 & 1
  \end{array} \right)
\end{equation}

After this, the pose of the gripper $P_{\text{gripper}}$ corresponding to the obtained
tool's pose can be obtained by solving the relative geometrical
equation:

\begin{eqnarray}
  P_{\text{gripper}} P_{\text{g,t}} &=& P_{\text{tool}} \\
  & \Updownarrow & \nonumber \\
  P_{\text{gripper}} &=& P_{\text{tool}}P_{\text{g,t}}^{-1}
\end{eqnarray}

here, $P_{\text{g,t}}$ is the affine transformation representing the
pose of the tool into the gripper's reference frame.

